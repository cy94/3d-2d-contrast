{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202361bf-3a50-4f0e-ac68-2d703cfbf226",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e3f38-6037-4ff9-8c8a-7a0a04aab107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, os.path as osp\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.scannet.utils_3d import ProjectionHelper, adjust_intrinsic, make_intrinsic, load_intrinsic, load_pose\n",
    "from datasets.scannet.utils_3d import load_depth, load_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0923236-79b1-4804-b4c7-108896794137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_name(scene_id, scan_id):\n",
    "    return f'scene{str(scene_id).zfill(4)}_{str(scan_id).zfill(2)}'\n",
    "\n",
    "# globals\n",
    "subvol_size = (32, 32, 64)\n",
    "voxel_size = 0.05\n",
    "voxel_dims = (1, 1, 1)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "proj_img_size = (40, 30)\n",
    "\n",
    "data_dir = Path('/mnt/data/scannet/backproj')\n",
    "fname = 'val-v7.h5'\n",
    "f = h5py.File(data_dir / fname, 'r')\n",
    "f['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d04263-f36d-40cb-9375-49223e5e3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(x, msg=''):\n",
    "    print(f'{msg} min: {int(x.min())}, max: {int(x.max())}, avg: {int(x.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907cf8b-e859-4d6d-bdad-f397efd80d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupied, projected, overlap = [], [], []\n",
    "skipped = 0\n",
    "for ndx in tqdm(range(f['x'].shape[0])):\n",
    "    w2g, sceneid, scanid, frames = f['world_to_grid'][ndx], f['scene_id'][ndx], f['scan_id'][ndx], f['frames'][ndx]\n",
    "\n",
    "    subvol_x = f['x'][ndx]\n",
    "    occupied.append((subvol_x == 1).sum())\n",
    "    # per-scene basics\n",
    "    scan_name = get_scan_name(sceneid, scanid)\n",
    "    frame_ndx = 0\n",
    "    # val set - no frame, skip\n",
    "    if frames[frame_ndx] == -1:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    pose_path = root / scan_name / 'pose' / f'{frames[frame_ndx]}.txt'\n",
    "    pose = load_pose(pose_path).numpy()\n",
    "    depth_path = root / scan_name / 'depth' / f'{frames[frame_ndx]}.png' \n",
    "    depth = load_depth(depth_path, proj_img_size)\n",
    "    # get projection\n",
    "    intrinsic_path = root / scan_name / 'intrinsic/intrinsic_color.txt'\n",
    "    intrinsic = load_intrinsic(intrinsic_path)\n",
    "    # adjust for smaller image size\n",
    "    intrinsic = adjust_intrinsic(intrinsic, [1296, 968], proj_img_size)\n",
    "\n",
    "    projection = ProjectionHelper(\n",
    "                intrinsic, \n",
    "                0.4, 4.0,\n",
    "                proj_img_size,\n",
    "                subvol_size, voxel_size\n",
    "            )\n",
    "\n",
    "    # projection expects origin of chunk in a corner\n",
    "    # but w2g is wrt center of the chunk -> add 16 to its \"grid coords\" to get the required grid coords\n",
    "    # ie 0,0,0 becomes 16,16,16\n",
    "    # add an additional translation to existing one \n",
    "    t = torch.eye(4)\n",
    "    t[:3, -1] = torch.Tensor(subvol_size)/2\n",
    "    w2g_tmp = t @ w2g\n",
    "\n",
    "    proj = projection.compute_projection(torch.Tensor(depth), torch.Tensor(pose), torch.Tensor(w2g_tmp))\n",
    "    if proj is None: \n",
    "        continue\n",
    "    proj3d, proj2d = proj\n",
    "    num_inds = proj3d[0]\n",
    "\n",
    "    ind3d = proj3d[1:1+num_inds]\n",
    "    ind2d = proj2d[1:1+num_inds]\n",
    "\n",
    "    coords_3d = ProjectionHelper.lin_ind_to_coords_static(ind3d, subvol_size).T[:, :-1].long()\n",
    "    i,j,k = coords_3d.T\n",
    "\n",
    "    projected.append(proj3d[0].item())\n",
    "    \n",
    "    overlap.append((subvol_x[i, j, k] == 1).sum())\n",
    "\n",
    "print('Skipped:', skipped)\n",
    "projected = torch.Tensor(projected)\n",
    "occupied = torch.Tensor(occupied)\n",
    "overlap = torch.Tensor(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb5d39-0154-4a69-8ee2-d828f8826cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(occupied, 'occupied')\n",
    "stats(projected, 'projected')\n",
    "stats(overlap, 'overlap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725244c-d39b-438b-9417-f6d514b64d1f",
   "metadata": {},
   "source": [
    "# Indices vs coords - 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3932e1-54c0-4f13-8ddc-4fa8265a827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these many features in the volume\n",
    "num_ind = 10\n",
    "# pick the inds to set features\n",
    "inds = torch.randperm(32*32*32)[:num_ind]\n",
    "coords_3d = ProjectionHelper.lin_ind_to_coords_static(inds, subvol_size).T[:, :-1].long()\n",
    "i,j,k = coords_3d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b475149-2959-405d-9b3a-653f992355b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n1000 pass\n",
    "\n",
    "# empty features tensor CWHD\n",
    "x = torch.zeros(2, 32, 32, 32)\n",
    "# set using indices -> dont reshape, may create a new tensor\n",
    "# CDHW\n",
    "x = x.permute(0, 3, 2, 1).contiguous()\n",
    "x.view(2, -1)[:, inds] = torch.ones(2, num_ind)\n",
    "# back to CWHD\n",
    "x = x.permute(0, 3, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab2bf9-f984-4a12-87af-feb7c0675641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n1000 pass\n",
    "\n",
    "x = torch.zeros(2, 32, 32, 32)\n",
    "coords_3d = ProjectionHelper.lin_ind_to_coords_static(inds, subvol_size).T[:, :-1].long()\n",
    "i,j,k = coords_3d.T\n",
    "\n",
    "# empty features tensor CWHD\n",
    "x = torch.zeros(2, 32, 32, 32)\n",
    "\n",
    "# set values with ijk\n",
    "x[:, i, j, k] = torch.ones(2, num_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e18f6-0851-433c-95c6-9a3c2e795d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWHD, then use coords\n",
    "print(x[:, i, j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d0cde-5d0b-4e89-ab5c-96fe3ad95585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDHW, then use inds\n",
    "print(x.permute(0, 3, 2, 1).reshape(2, -1)[:, inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f196a7c-4df1-42a0-bf5b-18d1844f63d5",
   "metadata": {},
   "source": [
    "# Indices vs coords in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483de6cd-ea59-4773-b5df-5672c4f667d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (40, 30)\n",
    "num_ind = 10\n",
    "inds2d = torch.randperm(img_size[0]*img_size[1])[:num_ind]\n",
    "# coords\n",
    "coords_2d = ProjectionHelper.lin_ind2d_to_coords2d_static(inds2d, (img_size))\n",
    "i, j = coords_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58680909-b93b-44f9-9c7b-435d6063cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1000 pass\n",
    "\n",
    "# CHW image\n",
    "x2d = torch.zeros(2, img_size[1], img_size[0])\n",
    "\n",
    "# set features using linear indices in CHW\n",
    "# CWH\n",
    "x2d.view(2, -1)[:, inds2d] = torch.ones(2, num_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876831b-137f-4863-b745-34282c15428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1000 pass\n",
    "\n",
    "# CHW image\n",
    "x2d = torch.zeros(2, img_size[1], img_size[0])\n",
    "\n",
    "# get coords\n",
    "coords_2d = ProjectionHelper.lin_ind2d_to_coords2d_static(inds2d, (img_size))\n",
    "i, j = coords_2d\n",
    "\n",
    "# set features in CWH using coords\n",
    "x2d = x2d.permute(0, 2, 1)\n",
    "x2d[:, i, j] = torch.ones(2, num_ind)\n",
    "# back to CHW\n",
    "x2d = x2d.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182c8aa-4e25-4513-bf68-956a16cdc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use coords to index into CWH\n",
    "x2d.permute(0, 2, 1)[:, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887bef2-60a4-46d9-a2ab-894dffd83f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use inds to index into CHW\n",
    "x2d.view(2, -1)[:, inds2d]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
