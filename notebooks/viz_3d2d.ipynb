{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c52d06-8487-4a80-b3be-56b77baf18ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198dc03e-1bb9-4a00-871e-1e5807b6cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import trimesh\n",
    "import pyrender\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, os.path as osp\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.scannet.utils_3d import ProjectionHelper, adjust_intrinsic, make_intrinsic, load_intrinsic, load_pose\n",
    "from datasets.scannet.utils_3d import load_depth, load_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3294419-1a37-4905-a6c8-e055984bbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_name(scene_id, scan_id):\n",
    "    return f'scene{str(scene_id).zfill(4)}_{str(scan_id).zfill(2)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80458c51-6694-4050-b364-dca72631c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol_size = (32, 32, 32)\n",
    "voxel_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516e802-57e6-4f88-a396-1376265e06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/mnt/data/scannet/backproj')\n",
    "fname = 'train50-v2.h5'\n",
    "f = h5py.File(data_dir / fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac40dc5-356e-4f37-976d-0f6e6228fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.keys())\n",
    "print(f['x'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115cbdb-ae72-48bf-a12f-2c98366389f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx =  50\n",
    "w2g, sceneid, scanid, frames = f['world_to_grid'][ndx], f['scene_id'][ndx], f['scan_id'][ndx], f['frames'][ndx]\n",
    "print(w2g)\n",
    "print(sceneid, scanid)\n",
    "print(frames)\n",
    "g2w = torch.inverse(torch.Tensor(w2g)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922971f-7906-4ac3-a800-ea1cfb10902c",
   "metadata": {},
   "source": [
    "## Draw only the scene and camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8de3ef-91d7-4b8a-921c-b2d0f60d511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = trimesh.scene.scene.Scene() \n",
    "\n",
    "# basics\n",
    "scan_name = get_scan_name(sceneid, scanid)\n",
    "print(scan_name)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "\n",
    "# camera and frustum\n",
    "intrinsic = make_intrinsic(1170.187988, 1170.187988, 647.75, 483.75)\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], (40, 30))\n",
    "\n",
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1])\n",
    "cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "\n",
    "camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "camball.apply_transform(pose)\n",
    "campath.apply_transform(pose)\n",
    "campath.colors = np.ones((5, 3)) * np.array((0, 255, 0))\n",
    "print('Add cam')\n",
    "scene.add_geometry(camball)\n",
    "scene.add_geometry(campath)\n",
    "\n",
    "# the scene mesh\n",
    "scan_path = root / f'{scan_name}/{scan_name}_vh_clean_2.ply'\n",
    "print(scan_path)\n",
    "scan = trimesh.load(scan_path)\n",
    "print(scan)\n",
    "print('Add scan')\n",
    "scene.add_geometry(scan)\n",
    "\n",
    "# axes\n",
    "axes = trimesh.creation.axis(axis_radius=0.1, axis_length=10)\n",
    "print('Add axes')\n",
    "scene.add_geometry(axes)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b85ad9-4c89-40fc-bf04-f97aa2a250f9",
   "metadata": {},
   "source": [
    "## Draw one chunk and its corresponding camera pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926a3d2-8f6e-4fdf-b6eb-c9acca44ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene = trimesh.scene.scene.Scene() \n",
    "\n",
    "# basics\n",
    "scan_name = get_scan_name(sceneid, scanid)\n",
    "print(scan_name)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "\n",
    "# camera and frustum\n",
    "intrinsic = make_intrinsic(1170.187988, 1170.187988, 647.75, 483.75)\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], (40, 30))\n",
    "\n",
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1])\n",
    "cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "\n",
    "camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "camball.apply_transform(pose)\n",
    "campath.apply_transform(pose)\n",
    "campath.colors = np.ones((5, 3)) * np.array((0, 255, 0))\n",
    "print('Add cam')\n",
    "scene.add_geometry(camball)\n",
    "scene.add_geometry(campath)\n",
    "\n",
    "# the scene mesh\n",
    "scan_path = root / f'{scan_name}/{scan_name}_voxelized.ply'\n",
    "print(scan_path)\n",
    "scan = trimesh.load(scan_path)\n",
    "scan.vertices *= voxel_size\n",
    "print(scan)\n",
    "print('Add scan')\n",
    "scene.add_geometry(scan)\n",
    "\n",
    "# draw the chunk\n",
    "# required transform is wrt the center of the box, which is what we have\n",
    "# hence use the existing g2w\n",
    "box = trimesh.creation.box(subvol_size, g2w)\n",
    "print('Add box')\n",
    "scene.add_geometry(box)\n",
    "\n",
    "# axes\n",
    "axes = trimesh.creation.axis(axis_radius=0.1, axis_length=10)\n",
    "print('Add axes')\n",
    "scene.add_geometry(axes)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25851c31-83f0-437d-b157-9596b3abd79d",
   "metadata": {},
   "source": [
    "## Vis only occupied voxels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94f72d-7f08-4adf-8f8e-aea233b1bf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scene = trimesh.scene.scene.Scene() \n",
    "\n",
    "scan_name = get_scan_name(sceneid, scanid)\n",
    "print(scan_name)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "scan_path = root / f'{scan_name}/{scan_name}_voxelized.ply'\n",
    "print(scan_path)\n",
    "scan = trimesh.load(scan_path)\n",
    "scan.vertices *= voxel_size\n",
    "print(scan)\n",
    "print('Add scan')\n",
    "scene.add_geometry(scan)\n",
    "\n",
    "# get the actual subvol\n",
    "x = f['x'][ndx]\n",
    "voxel_dims = (1, 1, 1)\n",
    "\n",
    "print('Draw occupied voxels')\n",
    "for i in tqdm(range(subvol_size[0])):\n",
    "    for j in range(subvol_size[1]):\n",
    "        for k in range(subvol_size[2]):\n",
    "            if x[i, j, k] == 1:\n",
    "                # get the transformation of this voxel\n",
    "                # w2g is wrt center of the chunk, but ijk is wrt a corner of the chunk\n",
    "                # hence subtract half chunk size from ijk to get \"grid coord\"\n",
    "                t = torch.eye(4)\n",
    "                t[:3, -1] = -(torch.Tensor((i, j, k)) - 16)\n",
    "                \n",
    "                voxel_w2g = t @ w2g\n",
    "                voxel_g2w = torch.inverse(torch.Tensor(voxel_w2g)).numpy()\n",
    "                box = trimesh.creation.box(voxel_dims, voxel_g2w)\n",
    "                # make the box blue\n",
    "                box.visual.face_colors = np.zeros((12, 4)) + (0, 0, 255, 128)\n",
    "                box.visual.vertex_colors = np.zeros((8, 4)) + (0, 0, 255, 255)\n",
    "                scene.add_geometry(box)\n",
    "\n",
    "intrinsic = make_intrinsic(1170.187988, 1170.187988, 647.75, 483.75)\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], (40, 30))\n",
    "\n",
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1])\n",
    "cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "camball.apply_transform(pose)\n",
    "campath.apply_transform(pose)\n",
    "campath.colors = np.ones((5, 3)) * np.array((0, 255, 0))\n",
    "print('Add cam')\n",
    "scene.add_geometry(camball)\n",
    "scene.add_geometry(campath)\n",
    "\n",
    "axes = trimesh.creation.axis(axis_radius=0.1, axis_length=10)\n",
    "print('Add axes')\n",
    "scene.add_geometry(axes)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022468e-3922-42e9-a8e4-bb849da1b0a8",
   "metadata": {},
   "source": [
    "## project image to voxels and viz correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f35bd8-b944-45d5-9187-49fabcffc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_img_size = (40, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fd714-9669-49df-938d-f1d860aa4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511e771-363c-40d3-8186-f16798efe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_path = root / scan_name / 'depth' / f'{frames[0]}.png' \n",
    "# invert dims in the tensor\n",
    "# N, H, W -> torch nn convention\n",
    "depth_big = load_depth(depth_path, (640, 480))\n",
    "print(depth_big.shape)\n",
    "plt.imshow(depth_big)\n",
    "plt.axis('off')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40246cc-668a-4ca9-85d6-53ac06b03299",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_big.min(), depth_big.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca531e0d-bee2-4c11-b4ae-a7ff8ff01728",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_path = root / scan_name / 'depth' / f'{frames[0]}.png' \n",
    "# invert dims in the tensor\n",
    "# N, H, W -> torch nn convention\n",
    "depth = load_depth(depth_path, proj_img_size)\n",
    "print(depth.shape)\n",
    "plt.axis('off')\n",
    "plt.imshow(depth)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779e09c-c06e-4c58-aa67-ed03ff75b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth.min(), depth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06261b-af27-4328-8461-b1e40ce232f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original RGB image\n",
    "rgb_path = root / scan_name / 'color' / f'{frames[0]}.jpg' \n",
    "rgb = load_color(rgb_path, (320, 240))\n",
    "print(rgb.shape)\n",
    "plt.axis('off')\n",
    "plt.imshow(rgb.transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0048c-4de4-45d4-be0e-097202831d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small RGB image\n",
    "rgb_path = root / scan_name / 'color' / f'{frames[0]}.jpg' \n",
    "rgb = load_color(rgb_path, proj_img_size)\n",
    "print(rgb.shape)\n",
    "plt.axis('off')\n",
    "plt.imshow(rgb.transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d26b7-6d0d-4e61-8fd1-438d3e687f0b",
   "metadata": {},
   "source": [
    "## Draw correspondences between image/depth and chunk voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a73a22-43f7-488a-80ea-5bcd4febfc14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get projection\n",
    "intrinsic_path = root / scan_name / 'intrinsic/intrinsic_color.txt'\n",
    "intrinsic = load_intrinsic(intrinsic_path)\n",
    "# adjust for smaller image size\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], proj_img_size)\n",
    "\n",
    "projection = ProjectionHelper(\n",
    "            intrinsic, \n",
    "            0.4, 4.0,\n",
    "            proj_img_size,\n",
    "            subvol_size, voxel_size\n",
    "        )\n",
    "\n",
    "# projection expects origin of chunk in a corner\n",
    "# but w2g is wrt center of the chunk -> add 16 to its \"grid coords\" to get the required grid coords\n",
    "# ie 0,0,0 becomes 16,16,16\n",
    "# add an additional translation to existing one \n",
    "t = torch.eye(4)\n",
    "t[:3, -1] = 16\n",
    "w2g_tmp = t @ w2g\n",
    "\n",
    "proj3d, proj2d = projection.compute_projection(torch.Tensor(depth), torch.Tensor(pose), torch.Tensor(w2g_tmp))\n",
    "print(proj3d.shape, proj2d.shape)\n",
    "num_inds = proj3d[0]\n",
    "print('Num correspondences:', proj3d[0], proj2d[0])\n",
    "ind3d = proj3d[1:1+num_inds]\n",
    "ind2d = proj2d[1:1+num_inds]\n",
    "print(ind3d.min(), ind3d.max(), torch.unique(ind3d).shape, torch.prod(torch.Tensor(subvol_size)))\n",
    "print(ind2d.min(), ind2d.max(), torch.unique(ind2d).shape, torch.prod(torch.Tensor(proj_img_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96e2c6-3fb8-48ff-bbf3-2ba714a9824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.eye(4)\n",
    "t[:3, -1] = torch.Tensor((16, 16, 16))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c39d08-8f92-4486-9a48-431ee1e381ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of occupied voxels\n",
    "x = f['x'][ndx]\n",
    "print('Occupied voxels', (x == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cd01b-c206-4a5a-ba58-c7c7c04b2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ijk coordinates into the chunk (array indices)\n",
    "coords_3d = torch.empty(4, num_inds)\n",
    "coords_3d = ProjectionHelper.lin_ind_to_coords_static(ind3d, coords_3d, subvol_size).T[:, :-1].long()\n",
    "print('3d coords:', coords_3d.shape, coords_3d.dtype)\n",
    "# viz in red\n",
    "colors = torch.zeros(num_inds, 3, dtype=int)\n",
    "colors[:, 0] = (torch.arange(num_inds) * 255 / num_inds).floor()\n",
    "print('colors:', colors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5262c0-7836-48e7-9d2a-dfc56f28dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_3d.min(axis=0)[0], coords_3d.max(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a67107-508b-4bf9-8084-3f09aaf7cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_2d = torch.empty(2, num_inds, dtype=torch.long)\n",
    "coords_2d = ProjectionHelper.lin_ind2d_to_coords2d_static(ind2d, coords_2d, proj_img_size).T.numpy()\n",
    "\n",
    "color_2d = np.zeros(proj_img_size[::-1] + (3,), dtype=int)\n",
    "color_2d[coords_2d[:, 1], coords_2d[:, 0]] = colors\n",
    "plt.imshow(color_2d)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50979f-841c-4251-a450-00a4e6bed011",
   "metadata": {},
   "source": [
    "## draw occupied and mapped voxels with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039136ec-7d9a-4ed4-a713-e5942361e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = trimesh.scene.scene.Scene() \n",
    "\n",
    "scan_name = get_scan_name(sceneid, scanid)\n",
    "print(scan_name)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "scan_path = root / f'{scan_name}/{scan_name}_vh_clean_2.ply'\n",
    "print(scan_path)\n",
    "scan = trimesh.load(scan_path)\n",
    "print(scan)\n",
    "print('Add scan')\n",
    "scene.add_geometry(scan)\n",
    "\n",
    "# get the actual subvol\n",
    "x = f['x'][ndx]\n",
    "dims = x.shape\n",
    "voxel_dims = (1, 1, 1)\n",
    "\n",
    "print('Draw occupied voxels')\n",
    "for i in tqdm(range(dims[0])):\n",
    "    for j in range(dims[1]):\n",
    "        for k in range(dims[2]):\n",
    "            if x[i, j, k] == 1:\n",
    "                # get the transformation of this voxel\n",
    "                # w2g is wrt center of the chunk, but ijk is wrt a corner of the chunk\n",
    "                # hence subtract half chunk size from ijk to get \"grid coord\"\n",
    "                t = torch.eye(4)\n",
    "                t[:3, -1] = -(torch.Tensor((i, j, k)) - 16)\n",
    "                # add an additional translation to existing one\n",
    "                voxel_w2g = t @ w2g\n",
    "                voxel_g2w = torch.inverse(torch.Tensor(voxel_w2g)).numpy()\n",
    "                box = trimesh.creation.box(voxel_dims, voxel_g2w)\n",
    "                # make the box blue\n",
    "                box.visual.face_colors = np.zeros((12, 4)) + (0, 0, 255, 128)\n",
    "                box.visual.vertex_colors = np.zeros((8, 4)) + (0, 0, 255, 255)\n",
    "                scene.add_geometry(box)\n",
    "\n",
    "print('Draw mapped voxels')\n",
    "for coord_3d, color in tqdm(zip(coords_3d, colors)): \n",
    "    i, j, k = coord_3d.tolist()\n",
    "    # get the transformation of this voxel\n",
    "    # w2g is wrt center of the chunk, but ijk is wrt a corner of the chunk\n",
    "    # hence subtract half chunk size from ijk to get \"grid coord\"\n",
    "    t = torch.eye(4)\n",
    "    t[:3, -1] = -(torch.Tensor((i, j, k)) - 16)\n",
    "    # add an additional translation to existing one\n",
    "    voxel_w2g = t @ w2g\n",
    "    voxel_g2w = torch.inverse(torch.Tensor(voxel_w2g)).numpy()\n",
    "    box = trimesh.creation.box(voxel_dims, voxel_g2w)\n",
    "\n",
    "    color_tup = tuple(color.tolist())\n",
    "    box.visual.face_colors = np.zeros((12, 4)) + (color_tup + (128,))\n",
    "    box.visual.vertex_colors = np.zeros((8, 4)) + (color_tup + (255,))\n",
    "    scene.add_geometry(box)\n",
    "\n",
    "intrinsic = make_intrinsic(1170.187988, 1170.187988, 647.75, 483.75)\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], (40, 30))\n",
    "\n",
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1])\n",
    "cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "camball.apply_transform(pose)\n",
    "campath.apply_transform(pose)\n",
    "campath.colors = np.ones((5, 3)) * np.array((0, 255, 0))\n",
    "print('Add cam')\n",
    "scene.add_geometry(camball)\n",
    "scene.add_geometry(campath)\n",
    "\n",
    "axes = trimesh.creation.axis(axis_radius=0.1, axis_length=10)\n",
    "print('Add axes')\n",
    "scene.add_geometry(axes)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4583a39-032f-4dab-91f3-1a7b6c735e73",
   "metadata": {},
   "source": [
    "## Draw all the cameras in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508b34f-b9ad-468f-8116-be49a323b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all cameras in a scene\n",
    "scene = trimesh.scene.scene.Scene() \n",
    "\n",
    "scan_name = get_scan_name(sceneid, scanid)\n",
    "print(scan_name)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "scan_path = root / f'{scan_name}/{scan_name}_vh_clean_2.ply'\n",
    "scan = trimesh.load(scan_path)\n",
    "print(scan)\n",
    "print('Add scan')\n",
    "scene.add_geometry(scan)\n",
    "\n",
    "box = trimesh.creation.box(subvol_size, g2w)\n",
    "print('Add box')\n",
    "scene.add_geometry(box)\n",
    "\n",
    "intrinsic = make_intrinsic(1170.187988, 1170.187988, 647.75, 483.75)\n",
    "intrinsic = adjust_intrinsic(intrinsic, [1296, 968], (40, 30))\n",
    "pose_files = sorted(os.listdir(root / scan_name / 'pose'), key=lambda f: int(osp.splitext(f)[0]))\n",
    "pose_indices = range(0, len(pose_files), frame_skip)\n",
    "print('Add poses:', len(pose_indices))\n",
    "frame_skip = 40\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1]) \n",
    "for ndx, pose_ndx in enumerate(tqdm(pose_indices)):\n",
    "    pose_path = root / scan_name / 'pose' / pose_files[pose_ndx]\n",
    "    pose = load_pose(pose_path).numpy()\n",
    "    \n",
    "    cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "    camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "    \n",
    "    camball.apply_transform(pose)\n",
    "    campath.apply_transform(pose)\n",
    "    campath.colors = np.zeros((5, 3))\n",
    "    scene.add_geometry(camball)\n",
    "    scene.add_geometry(campath)\n",
    "\n",
    "# draw the best pose in a different color\n",
    "pose_path = root / scan_name / 'pose' / f'{frames[0]}.txt'\n",
    "pose = load_pose(pose_path).numpy()\n",
    "focal = (intrinsic[0, 0], intrinsic[1, 1])\n",
    "cam = trimesh.scene.Camera(name=f'{scan_name}_{frames[0]}', resolution=(40, 30), focal=focal, z_near=0.4, z_far=4.0) \n",
    "camball, campath = trimesh.creation.camera_marker(cam, marker_height=4, origin_size=0.05)\n",
    "camball.apply_transform(pose)\n",
    "campath.apply_transform(pose)\n",
    "# green\n",
    "campath.colors = np.ones((5, 3)) * np.array((0, 255, 0))\n",
    "print('Add cam')\n",
    "scene.add_geometry(camball)\n",
    "scene.add_geometry(campath)\n",
    "\n",
    "axes = trimesh.creation.axis(axis_radius=0.1, axis_length=10)\n",
    "print('Add axes')\n",
    "scene.add_geometry(axes)\n",
    "\n",
    "scene.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
