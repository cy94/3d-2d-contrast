{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f1ece-1730-41cb-a225-036c113c65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project 2d labels onto 3d and calculate IOU\n",
    "# over train/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953be4ed-626e-4e2c-8693-e9b5bd429808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bfa58-cd8c-49ce-a8bf-2aaee85582dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torch\n",
    "import os, os.path as osp\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from eval.common import ConfMat\n",
    "\n",
    "from datasets.scannet.utils_3d import ProjectionHelper, adjust_intrinsic, make_intrinsic, load_intrinsic, load_pose\n",
    "from datasets.scannet.utils_3d import load_depth\n",
    "from datasets.scannet.common import read_label_mapping, map_labels, nyu40_to_continuous\n",
    "from datasets.scannet.common import VALID_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b934a-4df1-47f6-aa0b-571c937f0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scan_name(scene_id, scan_id):\n",
    "    return f'scene{str(scene_id).zfill(4)}_{str(scan_id).zfill(2)}'\n",
    "\n",
    "# globals\n",
    "subvol_size = (32, 32, 64)\n",
    "voxel_size = 0.05\n",
    "voxel_dims = (1, 1, 1)\n",
    "root = Path('/mnt/data/scannet/scans')\n",
    "proj_img_size = (320, 240)\n",
    "scannet_to_nyu40 = read_label_mapping('/mnt/data/scannet/scannetv2-labels.combined.tsv')\n",
    "num_classes = 40\n",
    "\n",
    "data_dir = Path('/mnt/data/scannet/backproj')\n",
    "# fname = 'train100-v7.h5'\n",
    "fname = 'val-v8.h5'\n",
    "f = h5py.File(data_dir / fname, 'r')\n",
    "f['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b7e69-3a4d-41ab-a94e-f1131296544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6feb53-3ecd-43ac-bce1-5c893533cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init metrics\n",
    "confmat = ConfMat(num_classes)\n",
    "skipped = 0\n",
    "inds = list(range(len(f['x'])))\n",
    "random.shuffle(inds)\n",
    "inds = inds[:2000]\n",
    "not_occupied = 0\n",
    "\n",
    "for ndx in tqdm(range(len(f['x']))):\n",
    "# for ndx in tqdm(range(2000)):\n",
    "    w2g, sceneid, scanid, frames = f['world_to_grid'][ndx], f['scene_id'][ndx], f['scan_id'][ndx], f['frames'][ndx]\n",
    "\n",
    "    # ignore subvols that are not occupied (val set)\n",
    "    subvol_x = f['x'][ndx]\n",
    "    if (subvol_x == 1).sum() == 0:\n",
    "        not_occupied += 1\n",
    "        continue\n",
    "        \n",
    "    subvol_y = f['y'][ndx]\n",
    "    # per-scene basics\n",
    "    scan_name = get_scan_name(sceneid, scanid)\n",
    "    frame_ndx = 0\n",
    "    \n",
    "    # val set - no frame, then skip\n",
    "    if frames[frame_ndx] == -1:\n",
    "        skipped += 1\n",
    "        continue\n",
    "        \n",
    "    pose_path = root / scan_name / 'pose' / f'{frames[frame_ndx]}.txt'\n",
    "    pose = load_pose(pose_path).numpy()\n",
    "    depth_path = root / scan_name / 'depth' / f'{frames[frame_ndx]}.png' \n",
    "    depth = load_depth(depth_path, proj_img_size)\n",
    "    # get projection\n",
    "    intrinsic_path = root / scan_name / 'intrinsic/intrinsic_color.txt'\n",
    "    intrinsic = load_intrinsic(intrinsic_path)\n",
    "    # adjust for smaller image size\n",
    "    intrinsic = adjust_intrinsic(intrinsic, [1296, 968], proj_img_size)\n",
    "\n",
    "    projection = ProjectionHelper(\n",
    "                intrinsic, \n",
    "                0.4, 4.0,\n",
    "                proj_img_size,\n",
    "                subvol_size, voxel_size\n",
    "            )\n",
    "\n",
    "    proj = projection.compute_projection(torch.Tensor(depth), torch.Tensor(pose), torch.Tensor(w2g))\n",
    "    if proj is None: \n",
    "        continue\n",
    "    proj3d, proj2d = proj\n",
    "    num_inds = proj3d[0]\n",
    "\n",
    "    ind3d = proj3d[1:1+num_inds]\n",
    "    ind2d = proj2d[1:1+num_inds]\n",
    "\n",
    "    # load the label image\n",
    "    # same as ENet\n",
    "    label_path = root / scan_name / 'label-filt' / f'{frames[frame_ndx]}.png' \n",
    "    label_scannet = np.array(imageio.imread(label_path))\n",
    "    label_nyu40 = map_labels(label_scannet, scannet_to_nyu40)\n",
    "    # map from NYU40 labels to 0-39 + 40 (ignored) labels, H,W\n",
    "    y = nyu40_to_continuous(label_nyu40, ignore_label=num_classes, \n",
    "                                        num_classes=num_classes)\n",
    "    # resize label image here using the proper interpolation - no artifacts  \n",
    "    # dims: H,W                                     \n",
    "    y = cv2.resize(y, proj_img_size, interpolation=cv2.INTER_NEAREST)\n",
    "    y = torch.LongTensor(y.astype(np.int32))\n",
    "    \n",
    "    # labels at the required locations, index into H,W image\n",
    "    labels = y.view(-1)[ind2d]\n",
    "    # 40/ignore labels in 2d -> dont project \n",
    "    invalid_2d = (labels == num_classes)\n",
    "    valid_2d = torch.logical_not(invalid_2d)\n",
    "    \n",
    "    valid_ind2d = ind2d[valid_2d]\n",
    "    valid_ind3d = ind3d[valid_2d]\n",
    "    \n",
    "    labels = y.view(-1)[valid_ind2d]\n",
    "    \n",
    "    # get the label volume - DHW\n",
    "    # create empty volume with zeros\n",
    "    output = torch.zeros(subvol_size[2], subvol_size[1], subvol_size[0], dtype=int)\n",
    "    output.view(-1)[valid_ind3d] = labels.T\n",
    "    # update metric\n",
    "    subvol_y = torch.LongTensor(subvol_y).permute(2, 1, 0)\n",
    "    confmat.update(output, subvol_y)\n",
    "    \n",
    "# compute metric\n",
    "class_subset = np.array(VALID_CLASSES) - 1\n",
    "iou_subset = np.nanmean(confmat.ious[class_subset])\n",
    "acc_subset = np.nanmean(confmat.accs[class_subset])\n",
    "print(f'iou: {iou_subset:.3f}, acc: {acc_subset:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
