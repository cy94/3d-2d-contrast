data:
    root: /mnt/data/scannet/scans/
    label_file: /mnt/data/scannet/scannetv2-labels.combined.tsv
    train_file: /mnt/data/scannet/backproj/train-v13.h5
    # keep train labels only for these scenes
    filter_train_label: /mnt/data/scannet/limited_recon/seg_scenes/1.txt
    val_file: /mnt/data/scannet/backproj/val-v8.h5
    # 20 or 40 classes?
    num_classes: 40
    # padding value used in the target - usually = num_classes
    # since targets are 0..num_classes-1
    target_padding: 40
    # size of each subvol
    subvol_size: [32, 32, 64]
    # how many rgb images for each chunk (3DMV)
    num_nearest_images: 1
    # size of the image that "looks" at the voxel
    proj_img_size: [40, 30]
    rgb_img_size: [320, 240] 
    
    # side of each voxel in meters
    voxel_size: 0.05

    # min and max depth considered for projection
    depth_min: 0.4
    depth_max: 4.0

model: 
    name: UNet2D3D_3DMV
    name_2d: ENet #DeepLabv3 
    
    # concat 2d feats to the 3d network
    use_2dfeat: True

    # use 2d labels?
    train_2d: True
    augment_2d: True

    # 2d model checkpoint
    # this model will be overwritten if pretrained is specified
    # ckpt_2d: lightning_logs/version_705/checkpoints/last.ckpt

    # finetune the whole 2d network?
    # finetune_2d: true

    # load state dict from here
    # pretrained: lightning_logs/version_783/checkpoints/last.ckpt
    losses:
        - contrastive 
        - crossent
        - crossent2d
    contrastive:
        temperature: 0.04
        n_points: 8192

train:
    opt: 
        name: adam
        lr: 0.0001
        l2: 0.0000
    train_batch_size: 7
    val_batch_size: 7
    epochs: 3000
    class_weights: true
    eval_intv: 2000
    limit_val_batches: 1.0

    resume: null #lightning_logs/version_791/checkpoints/last.ckpt
